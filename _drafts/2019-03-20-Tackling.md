---
layout: default
title: "Tackling a problem"
---

# Tackling a problem


Data analysis
If you dont have a dataset and you need to make one, choose WHICH features are need to be stored.
if you have a dataset, clean up features that are unnecessary. Check the distributions of the features
Which are the inputs, which are the outputs. What is the objective and what assumptions do we make
Try to utilize any prior knowledge
Data quality assessment and outlier analysis

Data preprocessing and Feature analysis (low-level representation)
Dimensionality reduction using PCA, SOM, ICA to study data in lower dimensions
Make the transformation to the whole dataset. 
Rescale the data by subtracting the value from each element / feature of the input vector and divide by the variance.
Split into training, testing and validation sets (50:25:25)

Using ANN:
Select network architecture: The input and output layers are defined by the data and the problem. Selecting how many layers and how many nodes can be done through trial and error
Train using MLP and Early Stopping
Test to actually evaluate how good the modelâ€™s generalisation capabilities are.

General Optimizations:
Momentum
Weight decay
Mini batches
Learning rate decay (make large scale changes at the beginning when the weights are random)
Use antisymmetric activation function (?)
Weight more hard examples during training
Add random noise to the training examples so the model learns a more general representation (a new noise vector at each sample at each epoch)
Bootstrap
Cross validation
Leave one out estimate
Hyperparameter optimization

Specific strategies to specific problems:
Overfitting:
Validation set: During training we want to know how well our model is able to generalise and stop when it shows signs of overfitting. For this, we use a validation set in order to make sure the algorithm is able to learn.
Noise to train data
Underfitting:


Stuck in local minima:


Bias - Variance dilemma:
More training data
find optimal NN architecture
Optimize NN structure if there is a size problem:
network growing or pruning
Network topology constructed from simpler networks (network committees and mixture of experts)
Temporarily cheating: Feeding the algorithm the targets (or target features) as input
